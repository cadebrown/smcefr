<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Cade Brown cade@utk.edu" />
  <meta name="author" content="Piotr Luszczek" />
  <title>SMCEFR: Sentinel-3 Satellite Dataset</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">SMCEFR: Sentinel-3 Satellite Dataset</h1>
<p class="author">Cade Brown <a href="mailto:cade@utk.edu" class="email">cade@utk.edu</a></p>
<p class="author">Piotr Luszczek</p>
</header>
<p>Check out the source on GitHub: <a href="https://github.com/cadebrown/smcefr" class="uri">https://github.com/cadebrown/smcefr</a></p>
<p>Link to downloads: <a href="https://github.com/cadebrown/smcefr/releases" class="uri">https://github.com/cadebrown/smcefr/releases</a></p>
<h1 id="introduction">Introduction</h1>
<figure>
<img src="https://cade.site/files/smcefr/miniset.jpg" id="smcefr-18" alt="" /><figcaption>Figure 1: A sample of 18 images from the <code>smcefr-mini</code> dataset</figcaption>
</figure>
<p>Satellite data is important for many environmental sciences, as they give scientists a bird’s eye view of large areas of the Earth. Modern orbital sensor allow them to collect additional research input remotely with high precision in order to emply data-intensive analysis workflows. For example, the Sentinel-3 satellite collects images that are used by scientists for a wide variety of research tasks, such as monitoring ocean and land surface temperatures, bootstrapping models for weather forecasts or atmospheric conditions’ prediction, and modeling and predicting climate change.</p>
<p>However, in its original form, the data size and the format are unwieldy for rapid data exploration. Our goal was to remedy this by simplifying the dataset. To this end, it has been prepossessed to use a more approachable format, which is described in Section <a href="#DS" data-reference-type="ref" data-reference="DS">2</a>, but here is a brief overview:</p>
<p>SMCEFR: Sentinel-3 Satellite is a dataset consisting of 1024x1024 red-gree-blue (RGB) images generated from the Sentinel-3 satellite via the Ocean and Land Color Instrument (OLCI). In order to facilitate the competition challenge we applied simplifications to the original and reduced the data volume. This preprocessing created a subset of the data and produced RGB images that are easier to analyze with model prototypes using tools like Python and NumPy/Pillow modules or Tensorflow or OpenCV in C++ and many other modern image processing software. Our goal was to give the participants the ability to rapidly test and visualize their algorithms. Furthermore, we posed challenge questions to guide the potential research directions for the participants could explore to present their own insights. In particular, we encourage approaches originating from computer vision, numerical programming, and machine learning.</p>
<h1 id="DS">Data Source</h1>
<p>The original data for this dataset came from the Copernicus Hub <a href="#R2">[2]</a>, which hosts large-scale historical records allowing access to multi-sensor data. However, the hub’s access policy requires a complicated workflow to query, filter, download, and preprocess the available datasets. We recongize the need of the full applications to have accesss to the extra geospatial and spectral information. While this could be extremely useful, for the purposes of a data challenge competition with a broad appeal, a smaller and more manageable dataset is desirable. In the following, we summarize the specifications that guided the creation of this dataset, which we will call <code>SMCEFR</code> (SMC’s Earth Full Resolution):</p>
<ul>
<li><p>Data from the Ocean Land and Color Instrument (OLCI) on the Sentinel-3 was queried.</p></li>
<li><p>Data was considered from the OLCI’s Earth Full Resolution (EFR) data product <a href="#R3">[3]</a>.</p></li>
<li><p>Only the scans visualizating a part of the North or Sourth American continents were used, to provide a more consistent dataset.</p></li>
<li><p>Data from the selected time periods and only in the past 3 years were used.</p></li>
<li><p>All images are center-cropped to the exact 1024x1024 resolution, or were discarded if only a smaller image was available. This naturally avoided the need for normalization and resizing.</p></li>
<li><p>Multispectral data (20+ bands) are reduced to standard visible RGB representation to reduce the dimensionality.</p></li>
<li><p>The images with the most extreme cases of sparsity or low-entropy were discarded. For example, images that are completely white or blue which represented dense cloud cover or ocean water, respectively.</p></li>
</ul>
<p>In the end, we produced smaller scale datasets in specific sizes, and encoded as traditional RGB images (PNG image format) with a 1024x1024 size. Figure <a href="#smcefr-18" data-reference-type="ref" data-reference="smcefr-18">1</a> presents a sample of 18 images from our reduced data set. These are available from the GitHub release page <a href="#R1">[1]</a>, and are meant to be easily accessible using any of the following software packages or workflows:</p>
<ul>
<li><p>Python with NumPy/SciPy, Pillow, Pandas modules.</p></li>
<li><p>Python with OpenCV module.</p></li>
<li><p>Python with Tensorflow or PyTorch.</p></li>
</ul>
<h2 id="filename-schema">Filename Schema</h2>
<p>For clear identification, the PNG images in the dataset are named by followiing a strict scheme and the details of the format are described in Figure <a href="#sen3-fname" data-reference-type="ref" data-reference="sen3-fname">2</a>. Although this information is auxiliary for most intended processing scenarios, it could serve as additional input and guide supervision during training.</p>
<figure>
<img src="https://cade.site/files/smcefr/filename.png" id="sen3-fname" alt="" /><figcaption>Figure 2: Sentinel-3 Generic Filename Schema Image</figcaption>
</figure>
<h2 id="accessing-dataset">Accessing Dataset</h2>
<p>Our dataset is available for download on GitHub <a href="#R1">[1]</a>. The dowload is compact: it is a single Tar file compressed with Gzip (<a href="https://drive.google.com/file/d/1HHSqd7LYi1npEqHD_frCgOSGa5VrvALy/view">smcefr-full.tar.gz</a>). The location of the file is <a href="https://drive.google.com/file/d/1HHSqd7LYi1npEqHD_frCgOSGa5VrvALy/view">https://drive.google.com/file/d/1HHSqd7LYi1npEqHD_frCgOSGa5VrvALy/view</a> and it can be expanded with the command:</p>
<pre class="shell"><code>$ tar -xvf smcefr-full.tar.gz</code></pre>
<p>which will create a directory that contains all the PNG files we selected. These can then be easily read with the OpenCV library, Python’s Pillow, Tensorflow, and many other media frameworks.</p>
<p>Additionally, the source code and implementations for the dataset reduction mentioned above can be found on GitHub <a href="#R1">[1]</a>.</p>
<p>There is also a smaller version: (<a href="smcefr-mini.tar.gz">smcefr-mini.tar.gz</a>). The location of the file is <a href="https://github.com/cadebrown/smcefr/releases/download/v1.0.0/smcefr-mini.tar.gz">github.com/cadebrown/smcefr/releases/download/v1.0.0/smcefr-mini.tar.gz</a> and it can be expanded with the command:</p>
<h2 id="reporting-problems">Reporting Problems</h2>
<p>If any errors arise during the usage of the dataset, an issue can be filed on the GitHub page <a href="#R1">[1]</a>, or by directly contacting the authors of this paper: corresponding author is Cade Brown, .</p>
<h1 id="challenge-questions">Challenge Questions</h1>
<p>To motivate the potential analysis methods for the dataset, we present below sample challenge questions and directions that explore the prospective ideas in data science, computer vision, and machine learning.</p>
<h2 id="cloud-identification-1">Cloud Identification (#1)</h2>
<p>What methods can be used to segment and identify the regions of the images that are partially or completely obstructed by the cloud cover?</p>
<p>Potential approaches:</p>
<ul>
<li><p>Computer Vision: thresholding, K-means clustering, and edge detection should allow for a straightforward identification of clouds as a mask or segmentation map.</p></li>
<li><p>Machine Learning: many methods could be used, for example, the U-Net architecture <a href="#R4">[4]</a>. Most methods would require some ground truth dataset, i.e., using supervised machine learning. Also, unsupervised clustering followed by a programmer-assisted classification on the learned clustering patterns could be used as well. i.e., using unsupervised machine learning. A survey of available methods is available online by Sanatan Mishra <a href="#R5">[5]</a>.</p></li>
</ul>
<h2 id="noise-removal-2">Noise Removal (#2)</h2>
<p>Consider a case where the sensor data is incomplete, of varied quality, or totally degraded. Is there any way to take partially damaged/noisy data, and reconstruct something “closer” to the original sensor reading?</p>
<p>Be sure to consider the measure “closeness” carefully. For example, can useful metrics (PSNR, MSE) be used to compare performance of various methods?</p>
<p>For this task, we suggest creating copies of the “ground truth” dataset, and then adding a random amount of noise, followed by processing the copy as input.</p>
<ul>
<li><p>Computer Vision: standard denoising techniques (Non-local Means Denoising, available in OpenCV <a href="#R6">[6]</a>) would produce usable results quite quickly.</p></li>
<li><p>Machine Learning: using unsupervised learning techniques, with the noise-augmented copies, one could use any number of optimization approaches. One example using Tensorflow that uses the concepts of autoencoders and latent space is available online <a href="#R7">[7]</a>. For using this approach, a good intro to latent space can be found online, written by Ekin Tui <a href="#R8">[8]</a>.</p></li>
</ul>
<h2 id="image-compression-3">Image Compression (#3)</h2>
<p>To preserve data integrity, the dataset is provided as PNG, in the lossless data compression format mode. However, for a variety of purposes, it would be useful to allow a small amount of error in exchange for an appreciatiable size reduction. What can research methods be used to save space while keeping the best quality possible?</p>
<ul>
<li><p>Numerical Programming: software libraries exist for HPC and scientific workloads, for example zfp <a href="#R9">[9]</a>, FFT, cosine transform, and wavelet-based methods.</p></li>
<li><p>Machine Learning: Using Generative Adversarial Networks (GANs), some models have been trained to perform image compression ~4x times better than JPEG, such as HIFIC <a href="#R10">[10]</a>, which comes with included pre-trained models and is freely available to download. For code samples and their documentation, see the Tensorflow Compression code <a href="#R11">[11]</a>. Additionally, a custom autoencoder could be trained specifically for the task, so that the compression is optimized for this dataset, and potentially allowing for even more fine-tuned performance in terms of the compression ratio.</p></li>
</ul>
<h1 id="references">References</h1>
<p><a name="R1">[1]</a> Cade Brown: <em>SMCEFR: Sentinel-3 Satellite Dataset</em> <a href="https://github.com/cadebrown/smcefr" class="uri">https://github.com/cadebrown/smcefr</a></p>
<p>Google Drive: Dataset Download <code>smcefr-full</code> (2.6GB) <a href="https://drive.google.com/file/d/1HHSqd7LYi1npEqHD_frCgOSGa5VrvALy/view" class="uri">https://drive.google.com/file/d/1HHSqd7LYi1npEqHD_frCgOSGa5VrvALy/view</a>.</p>
<p>GitHub: Dataset Download: <code>smcefr-mini</code>(1GB) <a href="https://github.com/cadebrown/smcefr/releases/download/v1.0.0/smcefr-full.tar.gz" class="uri">https://github.com/cadebrown/smcefr/releases/download/v1.0.0/smcefr-full.tar.gz</a>.</p>
<p><a name="R2">[2]</a> Copernicus Open Access Hub, <a href="https://scihub.copernicus.eu/" class="uri">https://scihub.copernicus.eu/</a>.</p>
<p><a name="R3">[3]</a> Sentinel-3 OLCI EFR Data Product Description, <a href="https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-3-olci/level-1/fr-or-rr-toa-radiances" class="uri">https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-3-olci/level-1/fr-or-rr-toa-radiances</a>.</p>
<p><a name="R4">[4]</a> Olaf Ronneberger, Philipp Fischer, Thomas Brox: <em>U-Net: Convolutional Networks for Biomedical Image Segmentation.</em> MICCAI Springer, LNCS, Vol.9351: 234–241, 2015. <a href="https://arxiv.org/pdf/1505.04597.pdf" class="uri">https://arxiv.org/pdf/1505.04597.pdf</a></p>
<p><a name="R5">[5]</a> Sanatan Mishra: <em>Unsupervised Learning and Data Clustering.</em> <a href="https://towardsdatascience.com/unsupervised-learning-and-data-clustering-eeecb78b422a" class="uri">https://towardsdatascience.com/unsupervised-learning-and-data-clustering-eeecb78b422a</a></p>
<p><a name="R6">[6]</a> OpenCV: <em>Image Denoising.</em> <a href="https://docs.opencv.org/3.4/d5/d69/tutorial_py_non_local_means.html" class="uri">https://docs.opencv.org/3.4/d5/d69/tutorial_py_non_local_means.html</a>.</p>
<p><a name="R7">[7]</a> Easy Tensorflow: <em>Noise Removal Autoencoder</em> <a href="https://www.easy-tensorflow.com/tf-tutorials/autoencoders/noise-removal" class="uri">https://www.easy-tensorflow.com/tf-tutorials/autoencoders/noise-removal</a></p>
<p><a name="R8">[8]</a> Ekin Tiu: <em>Understanding Latent Space in Machine Learning</em>. <a href="https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d" class="uri">https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d</a>.</p>
<p><a name="R9">[9]</a> zfp: <em>Compressed Floating-Point and Integer Arrays</em>. <a href="https://computing.llnl.gov/projects/zfp" class="uri">https://computing.llnl.gov/projects/zfp</a>.</p>
<p>Peter Lindstrom, <em>Fixed-Rate Compressed Floating-Point Arrays</em> IEEE Transactions on Visualization and Computer Graphics, 20(12): 2674–2683, December 2014, doi:10.1109/TVCG.2014.2346458. <a href="https://ieeexplore.ieee.org/document/6876024" class="uri">https://ieeexplore.ieee.org/document/6876024</a></p>
<p><a name="R10">[10]</a> Mentzer, Fabian and Toderici, George D and Tschannen, Michael and Agustsson, Eirikur: <em>High-Fidelity Generative Image Compression.</em> Advances in Neural Information Processing Systems, Vol.33, 2020 <a href="https://hific.github.io/" class="uri">https://hific.github.io/</a></p>
<p><a name="R11">[11]</a>Tensorflow Source Code: <em>Compression</em>. <a href="https://github.com/tensorflow/compression/tree/master/models/hific" class="uri">https://github.com/tensorflow/compression/tree/master/models/hific</a></p>
</body>
</html>
